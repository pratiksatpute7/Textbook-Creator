{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine learning', 'big data', 'artificial inttelligence']\n",
      "machine learning\n",
      "Already in database\n",
      "big data\n",
      "Already in database\n",
      "artificial inttelligence\n",
      "Not in DB\n",
      "<WikipediaPage 'Artificial intelligence'>\n",
      "https://en.wikipedia.org/wiki/Artificial_intelligence\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "import requests\n",
    "import bs4\n",
    "import pymongo\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import bs4 as BeautifulSoup\n",
    "import urllib.request  \n",
    "from mttkinter import *  \n",
    "from tkinter import *\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client.textbook\n",
    "col = db.index\n",
    "\n",
    "def _create_dictionary_table(text_string) -> dict:\n",
    "   \n",
    "    #removing stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = word_tokenize(text_string)\n",
    "    \n",
    "    #reducing words to their root form\n",
    "    stem = PorterStemmer()\n",
    "    \n",
    "    #creating dictionary for the word frequency table\n",
    "    frequency_table = dict()\n",
    "    for wd in words:\n",
    "        wd = stem.stem(wd)\n",
    "        if wd in stop_words:\n",
    "            continue\n",
    "        if wd in frequency_table:\n",
    "            frequency_table[wd] += 1\n",
    "        else:\n",
    "            frequency_table[wd] = 1\n",
    "\n",
    "    return frequency_table\n",
    "\n",
    "def _calculate_sentence_scores(sentences, frequency_table) -> dict:   \n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_weight = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount = (len(word_tokenize(sentence)))\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "        for word_weight in frequency_table:\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "                if sentence[:7] in sentence_weight:\n",
    "                    sentence_weight[sentence[:7]] += frequency_table[word_weight]\n",
    "                else:\n",
    "                    sentence_weight[sentence[:7]] = frequency_table[word_weight]\n",
    "\n",
    "        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words\n",
    "\n",
    "       \n",
    "\n",
    "    return sentence_weight\n",
    "\n",
    "def _calculate_average_score(sentence_weight) -> int:\n",
    "   \n",
    "    #calculating the average score for the sentences\n",
    "    sum_values = 0\n",
    "    for entry in sentence_weight:\n",
    "        sum_values += sentence_weight[entry]\n",
    "\n",
    "    #getting sentence average value from source text\n",
    "    average_score = (sum_values / len(sentence_weight))\n",
    "\n",
    "    return average_score\n",
    "\n",
    "def _get_article_summary(sentences, sentence_weight, threshold):\n",
    "    sentence_counter = 0\n",
    "    article_summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] >= (threshold):\n",
    "            article_summary += \" \" + sentence\n",
    "            sentence_counter += 1\n",
    "\n",
    "    return article_summary\n",
    "\n",
    "def _run_article_summary(article):\n",
    "    \n",
    "    #creating a dictionary for the word frequency table\n",
    "    frequency_table = _create_dictionary_table(article)\n",
    "\n",
    "    #tokenizing the sentences\n",
    "    sentences = sent_tokenize(article)\n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_scores = _calculate_sentence_scores(sentences, frequency_table)\n",
    "\n",
    "    #getting the threshold\n",
    "    threshold = _calculate_average_score(sentence_scores)\n",
    "\n",
    "    #producing the summary\n",
    "    article_summary = _get_article_summary(sentences, sentence_scores, 1.5 * threshold)\n",
    "\n",
    "    return article_summary\n",
    "\n",
    "\n",
    "#index = input(\"Enter search term : \")\n",
    "#l = []\n",
    "#l.append(index)\n",
    "\n",
    "#fh1 = open('topics.txt','r')\n",
    "#l = fh1.readlines()\n",
    "#fh1.close()\n",
    "\n",
    "def summarizeFunc():\n",
    "    for z in range(0,len(topicsToSearch)):\n",
    "\n",
    "        index =(topicsToSearch[z].strip()).lower()\n",
    "        print(index)\n",
    "        if(index!=''):\n",
    "            try :\n",
    "\n",
    "                dis = col.find_one({\"topic\": index},{\"_id\": 0})\n",
    "                fh = open('demo2.txt', \"a+\", encoding = \"utf-8\")\n",
    "            \n",
    "                count1 = 0\n",
    "                for vals in dis.values():\n",
    "\n",
    "                    if(count1==0):\n",
    "                        count1=count1+1\n",
    "                        vals=vals.upper()\n",
    "                        #print(vals)\n",
    "                        fh.write(vals)\n",
    "                    else:\n",
    "                        article_content = ''\n",
    "                        article_content+=vals\n",
    "                        #print(article_content)\n",
    "                        if __name__ == '__main__':\n",
    "                            summary_results = _run_article_summary(article_content)\n",
    "                            #print(summary_results)\n",
    "\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "                        fh.write(summary_results)\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "\n",
    "                fh.close()\n",
    "                print(\"Already in database\")\n",
    "\n",
    "\n",
    "            except:\n",
    "\n",
    "                print('Not in DB')\n",
    "                try:\n",
    "\n",
    "                    src = wikipedia.page(index)\n",
    "                    print(src)\n",
    "                    print(src.url)\n",
    "\n",
    "                except:\n",
    "                    print(index+\" no url found \")\n",
    "                    continue \n",
    "\n",
    "                res = requests.get(src.url)\n",
    "\n",
    "\n",
    "                soup = bs4.BeautifulSoup(res.text,'html.parser')\n",
    "                #print(soup)\n",
    "\n",
    "                fh = open('demo1.txt', \"w+\", encoding = \"utf-8\") \n",
    "                #for j in soup.select('h'):\n",
    "                #    print(j.text)\n",
    "                #count = 0\n",
    "                fh.write(index)\n",
    "                fh.write('\\n')\n",
    "                for i in soup.select('p'):\n",
    "                    #if(count == 5):\n",
    "                     #   break;\n",
    "                    #else:\n",
    "                    #type(i.text)\n",
    "                    fh.write(i.text)\n",
    "                    #print(i.text)\n",
    "                    #count = count + 1\n",
    "                fh.close()\n",
    "\n",
    "\n",
    "                fh = open('demo1.txt', \"r\", encoding = \"utf-8\")\n",
    "\n",
    "                t1 = fh.read()\n",
    "                t1 = re.sub(\"[\\[].*?[\\]]\", \"\", t1)\n",
    "                t1 = re.sub(r' {[^}]*}','',t1)\n",
    "                #print(type(t1))\n",
    "                dict1 = {\"topic\": index, \"value\": t1}\n",
    "                col.insert_one(dict1)\n",
    "                fh.close()\n",
    "\n",
    "                #query = {\"name\": index}\n",
    "                #doc = col.find(query)\n",
    "                #for x in doc:\n",
    "                #    print(x)\n",
    "\n",
    "                fh = open('demo2.txt', \"a+\", encoding = \"utf-8\")\n",
    "                #pprint.pprint(col.find_one({\"name\": index},{\"value\": 1}))\n",
    "                dis = col.find_one({\"topic\": index},{\"_id\": 0})\n",
    "                count1=0\n",
    "                for vals in dis.values():\n",
    "                #for i in range(0,1):\n",
    "\n",
    "                    if(count1==0):\n",
    "                        count1=count1+1\n",
    "                        vals=vals.upper()\n",
    "                        #print(vals)\n",
    "                        fh.write(vals)\n",
    "                    else:\n",
    "                        article_content = ''\n",
    "                        article_content+=vals\n",
    "                        #print(article_content)\n",
    "\n",
    "                        if __name__ == '__main__':\n",
    "                            summary_results = _run_article_summary(article_content)\n",
    "                            #print(summary_results)\n",
    "\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "                        fh.write(summary_results)\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "                fh.close()\n",
    "        else: \n",
    "            continue \n",
    "\n",
    "\n",
    "def expand():\n",
    "    \n",
    "    for i in range(int(subtopicNum.get())):\n",
    "        temp=StringVar()\n",
    "        subtopicLabel = Label(parent,text = \"Subtopic \"+str(i+1)+':',background='#00074f',foreground='white',font = \"Helvetica 20 bold\").grid(row = 5+i, column = 0,pady=20,padx=20) \n",
    "        subtopicEntry = Entry(parent,textvariable=temp,font = \"Helvetica 20 bold\").grid(row = 5+i, column = 1,pady=20,padx=20) \n",
    "        subtopicList.append(temp)\n",
    "    generate = Button(parent,bg='white', text = \"Generate Book\", command=printBook,font = \"Helvetica 20 bold\")\n",
    "    generate.grid(row = int(subtopicNum.get())+5 , column = 0,pady=20,padx=20)  \n",
    "\n",
    "def printBook():\n",
    "    topicsToSearch.append(titleName.get())\n",
    "    for i in subtopicList:\n",
    "        topicsToSearch.append(i.get())\n",
    "    print(topicsToSearch)\n",
    "    summarizeFunc()\n",
    "\n",
    "parent = mtTkinter.Tk()  \n",
    "parent.configure(background='#00074f')\n",
    "\n",
    "titleName=StringVar()\n",
    "subtopicNum=StringVar()\n",
    "subtopicList=[]\n",
    "topicsToSearch=[] #this is the list that is printing so use this to search and create document \n",
    "#just put a for loop over your code and feed what ever is in the list \n",
    "\n",
    "titleLabel = Label(parent,background='#00074f',foreground='white',text = \"Title\",font = \"Helvetica 20 bold\").grid(row = 0, column = 0,pady=20,padx=20) \n",
    "subtopicLabel = Label(parent,background='#00074f',foreground='white',text = \"Number of subtopics\",font = \"Helvetica 20 bold\").grid(row = 1, column = 0,pady=20,padx=20) \n",
    "\n",
    "titleEntry = Entry(parent,textvariable=titleName,font = \"Helvetica 20 bold\").grid(row = 0, column = 1,pady=20,padx=20)  \n",
    "subtopicEntry = Entry(parent,textvariable=subtopicNum,font = \"Helvetica 20 bold\").grid(row = 1, column = 1,pady=20,padx=20)  \n",
    "\n",
    "expand = Button(parent, text = \"Expand\",bg='white', command=expand,font = \"Helvetica 20 bold\")\n",
    "expand.grid(row = 4, column = 0,pady=20,padx=20)  \n",
    "\n",
    "parent.mainloop()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
