{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\91996\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-1-1c5726ce2764>\", line 236, in expand\n",
      "    for i in range(int(subtopicNum.get())):\n",
      "ValueError: invalid literal for int() with base 10: ''\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\91996\\Anaconda3\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-1-1c5726ce2764>\", line 236, in expand\n",
      "    for i in range(int(subtopicNum.get())):\n",
      "ValueError: invalid literal for int() with base 10: ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sachin tendulkar', 'world cup', 'cups']\n",
      "sachin tendulkar\n",
      "Already in database\n",
      "world cup\n",
      "Not in DB\n",
      "<WikipediaPage 'FIFA World Cup'>\n",
      "https://en.wikipedia.org/wiki/FIFA_World_Cup\n",
      "cups\n",
      "Not in DB\n",
      "<WikipediaPage 'CUPS'>\n",
      "https://en.wikipedia.org/wiki/CUPS\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "import requests\n",
    "import bs4\n",
    "import pymongo\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import bs4 as BeautifulSoup\n",
    "import urllib.request  \n",
    "from mttkinter import *  \n",
    "from tkinter import *\n",
    "\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client.textbook\n",
    "col = db.index\n",
    "\n",
    "def _create_dictionary_table(text_string) -> dict:\n",
    "   \n",
    "    #removing stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = word_tokenize(text_string)\n",
    "    \n",
    "    #reducing words to their root form\n",
    "    stem = PorterStemmer()\n",
    "    \n",
    "    #creating dictionary for the word frequency table\n",
    "    frequency_table = dict()\n",
    "    for wd in words:\n",
    "        wd = stem.stem(wd)\n",
    "        if wd in stop_words:\n",
    "            continue\n",
    "        if wd in frequency_table:\n",
    "            frequency_table[wd] += 1\n",
    "        else:\n",
    "            frequency_table[wd] = 1\n",
    "\n",
    "    return frequency_table\n",
    "\n",
    "def _calculate_sentence_scores(sentences, frequency_table) -> dict:   \n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_weight = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_wordcount = (len(word_tokenize(sentence)))\n",
    "        sentence_wordcount_without_stop_words = 0\n",
    "        for word_weight in frequency_table:\n",
    "            if word_weight in sentence.lower():\n",
    "                sentence_wordcount_without_stop_words += 1\n",
    "                if sentence[:7] in sentence_weight:\n",
    "                    sentence_weight[sentence[:7]] += frequency_table[word_weight]\n",
    "                else:\n",
    "                    sentence_weight[sentence[:7]] = frequency_table[word_weight]\n",
    "\n",
    "        sentence_weight[sentence[:7]] = sentence_weight[sentence[:7]] / sentence_wordcount_without_stop_words\n",
    "\n",
    "       \n",
    "\n",
    "    return sentence_weight\n",
    "\n",
    "def _calculate_average_score(sentence_weight) -> int:\n",
    "   \n",
    "    #calculating the average score for the sentences\n",
    "    sum_values = 0\n",
    "    for entry in sentence_weight:\n",
    "        sum_values += sentence_weight[entry]\n",
    "\n",
    "    #getting sentence average value from source text\n",
    "    average_score = (sum_values / len(sentence_weight))\n",
    "\n",
    "    return average_score\n",
    "\n",
    "def _get_article_summary(sentences, sentence_weight, threshold):\n",
    "    sentence_counter = 0\n",
    "    article_summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:7] in sentence_weight and sentence_weight[sentence[:7]] >= (threshold):\n",
    "            article_summary += \" \" + sentence\n",
    "            sentence_counter += 1\n",
    "\n",
    "    return article_summary\n",
    "\n",
    "def _run_article_summary(article):\n",
    "    \n",
    "    #creating a dictionary for the word frequency table\n",
    "    frequency_table = _create_dictionary_table(article)\n",
    "\n",
    "    #tokenizing the sentences\n",
    "    sentences = sent_tokenize(article)\n",
    "\n",
    "    #algorithm for scoring a sentence by its words\n",
    "    sentence_scores = _calculate_sentence_scores(sentences, frequency_table)\n",
    "\n",
    "    #getting the threshold\n",
    "    threshold = _calculate_average_score(sentence_scores)\n",
    "\n",
    "    #producing the summary\n",
    "    article_summary = _get_article_summary(sentences, sentence_scores, 1.5 * threshold)\n",
    "\n",
    "    return article_summary\n",
    "\n",
    "\n",
    "#index = input(\"Enter search term : \")\n",
    "#l = []\n",
    "#l.append(index)\n",
    "\n",
    "#fh1 = open('topics.txt','r')\n",
    "#l = fh1.readlines()\n",
    "#fh1.close()\n",
    "\n",
    "def summarizeFunc():\n",
    "    for z in range(0,len(topicsToSearch)):\n",
    "\n",
    "        index =(topicsToSearch[z].strip()).lower()\n",
    "        print(index)\n",
    "        if(index!=''):\n",
    "            try :\n",
    "\n",
    "                dis = col.find_one({\"topic\": index},{\"_id\": 0})\n",
    "                fh = open('demo2.txt', \"a+\", encoding = \"utf-8\")\n",
    "            \n",
    "                count1 = 0\n",
    "                for vals in dis.values():\n",
    "\n",
    "                    if(count1==0):\n",
    "                        count1=count1+1\n",
    "                        vals=vals.upper()\n",
    "                        #print(vals)\n",
    "                        fh.write(vals)\n",
    "                    else:\n",
    "                        article_content = ''\n",
    "                        article_content+=vals\n",
    "                        #print(article_content)\n",
    "                        if __name__ == '__main__':\n",
    "                            summary_results = _run_article_summary(article_content)\n",
    "                            #print(summary_results)\n",
    "\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "                        fh.write(summary_results)\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "\n",
    "                fh.close()\n",
    "                print(\"Already in database\")\n",
    "\n",
    "\n",
    "            except:\n",
    "\n",
    "                print('Not in DB')\n",
    "                try:\n",
    "\n",
    "                    src = wikipedia.page(index)\n",
    "                    print(src)\n",
    "                    print(src.url)\n",
    "\n",
    "                except:\n",
    "                    print(index+\" no url found \")\n",
    "                    continue \n",
    "\n",
    "                res = requests.get(src.url)\n",
    "\n",
    "\n",
    "                soup = bs4.BeautifulSoup(res.text,'html.parser')\n",
    "                #print(soup)\n",
    "\n",
    "                fh = open('demo1.txt', \"w+\", encoding = \"utf-8\") \n",
    "                #for j in soup.select('h'):\n",
    "                #    print(j.text)\n",
    "                #count = 0\n",
    "                fh.write(index)\n",
    "                fh.write('\\n')\n",
    "                for i in soup.select('p'):\n",
    "                    #if(count == 5):\n",
    "                     #   break;\n",
    "                    #else:\n",
    "                    #type(i.text)\n",
    "                    fh.write(i.text)\n",
    "                    #print(i.text)\n",
    "                    #count = count + 1\n",
    "                fh.close()\n",
    "\n",
    "\n",
    "                fh = open('demo1.txt', \"r\", encoding = \"utf-8\")\n",
    "\n",
    "                t1 = fh.read()\n",
    "                t1 = re.sub(\"[\\[].*?[\\]]\", \"\", t1)\n",
    "                t1 = re.sub(' {[^}]*}','',t1)\n",
    "                #print(type(t1))\n",
    "                dict1 = {\"topic\": index, \"value\": t1}\n",
    "                col.insert_one(dict1)\n",
    "                fh.close()\n",
    "\n",
    "                #query = {\"name\": index}\n",
    "                #doc = col.find(query)\n",
    "                #for x in doc:\n",
    "                #    print(x)\n",
    "\n",
    "                fh = open('demo2.txt', \"a+\", encoding = \"utf-8\")\n",
    "                #pprint.pprint(col.find_one({\"name\": index},{\"value\": 1}))\n",
    "                dis = col.find_one({\"topic\": index},{\"_id\": 0})\n",
    "                count1=0\n",
    "                for vals in dis.values():\n",
    "                #for i in range(0,1):\n",
    "\n",
    "                    if(count1==0):\n",
    "                        count1=count1+1\n",
    "                        vals=vals.upper()\n",
    "                        #print(vals)\n",
    "                        fh.write(vals)\n",
    "                    else:\n",
    "                        article_content = ''\n",
    "                        article_content+=vals\n",
    "                        #print(article_content)\n",
    "\n",
    "                        if __name__ == '__main__':\n",
    "                            summary_results = _run_article_summary(article_content)\n",
    "                            #print(summary_results)\n",
    "\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "                        fh.write(summary_results)\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "                        fh.write('\\n')\n",
    "                fh.close()\n",
    "        else: \n",
    "            continue \n",
    "\n",
    "\n",
    "def expand():\n",
    "    \n",
    "    for i in range(int(subtopicNum.get())):\n",
    "        temp=StringVar()\n",
    "        subtopicLabel = Label(parent,text = \"Subtopic \"+str(i+1)+':',background='#00074f',foreground='white',font = \"Helvetica 20 bold\").grid(row = 5+i, column = 0,pady=20,padx=20) \n",
    "        subtopicEntry = Entry(parent,textvariable=temp,font = \"Helvetica 20 bold\").grid(row = 5+i, column = 1,pady=20,padx=20) \n",
    "        subtopicList.append(temp)\n",
    "    generate = Button(parent,bg='white', text = \"Generate Book\", command=printBook,font = \"Helvetica 20 bold\")\n",
    "    generate.grid(row = int(subtopicNum.get())+5 , column = 0,pady=20,padx=20)  \n",
    "\n",
    "def printBook():\n",
    "    topicsToSearch.append(titleName.get())\n",
    "    for i in subtopicList:\n",
    "        topicsToSearch.append(i.get())\n",
    "    print(topicsToSearch)\n",
    "    summarizeFunc()\n",
    "\n",
    "parent = mtTkinter.Tk()  \n",
    "parent.configure(background='#00074f')\n",
    "\n",
    "titleName=StringVar()\n",
    "subtopicNum=StringVar()\n",
    "subtopicList=[]\n",
    "topicsToSearch=[] #this is the list that is printing so use this to search and create document \n",
    "#just put a for loop over your code and feed what ever is in the list \n",
    "\n",
    "titleLabel = Label(parent,background='#00074f',foreground='white',text = \"Title\",font = \"Helvetica 20 bold\").grid(row = 0, column = 0,pady=20,padx=20) \n",
    "subtopicLabel = Label(parent,background='#00074f',foreground='white',text = \"Number of subtopics\",font = \"Helvetica 20 bold\").grid(row = 1, column = 0,pady=20,padx=20) \n",
    "\n",
    "titleEntry = Entry(parent,textvariable=titleName,font = \"Helvetica 20 bold\").grid(row = 0, column = 1,pady=20,padx=20)  \n",
    "subtopicEntry = Entry(parent,textvariable=subtopicNum,font = \"Helvetica 20 bold\").grid(row = 1, column = 1,pady=20,padx=20)  \n",
    "\n",
    "expand = Button(parent, text = \"Expand\",bg='white', command=expand,font = \"Helvetica 20 bold\")\n",
    "expand.grid(row = 4, column = 0,pady=20,padx=20)  \n",
    "\n",
    "parent.mainloop()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear regression\n",
      "linear regression\n",
      "In statistics, linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables). The case of one explanatory variable is called simple linear regression. For more than one explanatory variable, the process is called multiple linear regression. This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable.\n",
      "In linear regression, the relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Such models are called linear models. Most commonly, the conditional mean of the response given the values of the explanatory variables (or predictors) is assumed to be an affine function of those values; less commonly, the conditional median or some other quantile is used. Like all forms of regression analysis, linear regression focuses on the conditional probability distribution of the response given the values of the predictors, rather than on the joint probability distribution of all of these variables, which is the domain of multivariate analysis.\n",
      "Linear regression was the first type of regression analysis to be studied rigorously, and to be used extensively in practical applications. This is because models which depend linearly on their unknown parameters are easier to fit than models which are non-linearly related to their parameters and because the statistical properties of the resulting estimators are easier to determine.\n",
      "Linear regression has many practical uses. Most applications fall into one of the following two broad categories:\n",
      "Linear regression models are often fitted using the least squares approach, but they may also be fitted in other ways, such as by minimizing the \"lack of fit\" in some other norm (as with least absolute deviations regression), or by minimizing a penalized version of the least squares cost function as in ridge regression (L2-norm penalty) and lasso (L1-norm penalty). Conversely, the least squares approach can be used to fit models that are not linear models. Thus, although the terms \"least squares\" and \"linear model\" are closely linked, they are not synonymous.\n",
      "Given a data set \n",
      "\n",
      "\n",
      "\n",
      "{\n",
      "\n",
      "y\n",
      "\n",
      "i\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "\n",
      "x\n",
      "\n",
      "i\n",
      "1\n",
      "\n",
      "\n",
      ",\n",
      "…\n",
      ",\n",
      "\n",
      "x\n",
      "\n",
      "i\n",
      "p\n",
      "\n",
      "\n",
      "\n",
      "}\n",
      "\n",
      "i\n",
      "=\n",
      "1\n",
      "\n",
      "\n",
      "n\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\\displaystyle \\{y_{i},\\,x_{i1},\\ldots ,x_{ip}\\}_{i=1}^{n}}\n",
      "\n",
      " of n statistical units, a linear regression model assumes that the relationship between the dependent variable y and the p-vector of regressors x is linear. This relationship is modeled through a disturbance term or error variable ε — an unobserved random variable that adds \"noise\" to the linear relationship between the dependent variable and regressors. Thus the model takes the form\n",
      "where T denotes the transpose, so that xiTβ is the inner product between vectors xi and β.\n",
      "Often these n equations are stacked together and written in matrix notation as\n",
      "where\n",
      "Some remarks on notation and terminology:\n",
      "Example. Consider a situation where a small ball is being tossed up in the air and then we measure its heights of ascent hi at various moments in time ti. Physics tells us that, ignoring the drag, the relationship can be modeled as\n",
      "where β1 determines the initial velocity of the ball, β2 is proportional to the standard gravity, and εi is due to measurement errors. Linear regression can be used to estimate the values of β1 and β2 from the measured data. This model is non-linear in the time variable, but it is linear in the parameters β1 and β2; if we take regressors xi = (xi1, xi2)  = (ti, ti2), the model takes on the standard form\n",
      "Standard linear regression models with standard estimation techniques make a number of assumptions about the predictor variables, the response variables and their relationship.  Numerous extensions have been developed that allow each of these assumptions to be relaxed (i.e. reduced to a weaker form), and in some cases eliminated entirely. Generally these extensions make the estimation procedure more complex and time-consuming, and may also require more data in order to produce an equally precise model.\n",
      "The following are the major assumptions made by standard linear regression models with standard estimation techniques (e.g. ordinary least squares):\n",
      "Beyond these assumptions, several other statistical properties of the data strongly influence the performance of different estimation methods:\n",
      "A fitted linear regression model can be used to identify the relationship between a single predictor variable xj and the response variable y when all the other predictor variables in the model are \"held fixed\". Specifically, the interpretation of βj is the expected change in y for a one-unit change in xj when the other covariates are held fixed—that is, the expected value of the partial derivative of y with respect to xj. This is sometimes called the unique effect of xj on y. In contrast, the marginal effect of xj on y can be assessed using a correlation coefficient or simple linear regression model relating only xj to y; this effect is the total derivative of y with respect to xj.\n",
      "Care must be taken when interpreting regression results, as some of the regressors may not allow for marginal changes (such as dummy variables, or the intercept term), while others cannot be held fixed (recall the example from the introduction: it would be impossible to \"hold ti fixed\" and at the same time change the value of ti2).\n",
      "It is possible that the unique effect can be nearly zero even when the marginal effect is large. This may imply that some other covariate captures all the information in xj, so that once that variable is in the model, there is no contribution of xj to the variation in y. Conversely, the unique effect of xj can be large while its marginal effect is nearly zero. This would happen if the other covariates explained a great deal of the variation of y, but they mainly explain variation in a way that is complementary to what is captured by xj. In this case, including the other variables in the model reduces the part of the variability of y that is unrelated to xj, thereby strengthening the apparent relationship with xj.\n",
      "The meaning of the expression \"held fixed\" may depend on how the values of the predictor variables arise. If the experimenter directly sets the values of the predictor variables according to a study design, the comparisons of interest may literally correspond to comparisons among units whose predictor variables have been \"held fixed\" by the experimenter. Alternatively, the expression \"held fixed\" can refer to a selection that takes place in the context of data analysis. In this case, we \"hold a variable fixed\" by restricting our attention to the subsets of the data that happen to have a common value for the given predictor variable. This is the only interpretation of \"held fixed\" that can be used in an observational study.\n",
      "The notion of a \"unique effect\" is appealing when studying a complex system where multiple interrelated components influence the response variable. In some cases, it can literally be interpreted as the causal effect of an intervention that is linked to the value of a predictor variable. However, it has been argued that in many cases multiple regression analysis fails to clarify the relationships between the predictor variables and the response variable when the predictors are correlated with each other and are not assigned following a study design. Commonality analysis may be helpful in disentangling the shared and unique impacts of correlated independent variables.\n",
      "Numerous extensions of linear regression have been developed, which allow some or all of the assumptions underlying the basic model to be relaxed.\n",
      "The very simplest case of a single scalar predictor variable x and a single scalar response variable y is known as simple linear regression.  The extension to multiple and/or vector-valued predictor variables (denoted with a capital X) is known as multiple linear regression, also known as multivariable linear regression.  Nearly all real-world regression models involve multiple predictors, and basic descriptions of linear regression are often phrased in terms of the multiple regression model.  Note, however, that in these cases the response variable y is still a scalar. Another term, multivariate linear regression, refers to cases where y is a vector, i.e., the same as general linear regression.\n",
      "The general linear model considers the situation when the response variable is not a scalar (for each observation) but a vector, yi. Conditional linearity of \n",
      "\n",
      "\n",
      "\n",
      "E\n",
      "(\n",
      "\n",
      "y\n",
      "\n",
      "∣\n",
      "\n",
      "\n",
      "x\n",
      "\n",
      "\n",
      "i\n",
      "\n",
      "\n",
      ")\n",
      "=\n",
      "\n",
      "\n",
      "x\n",
      "\n",
      "\n",
      "i\n",
      "\n",
      "\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "\n",
      "B\n",
      "\n",
      "\n",
      "{\\displaystyle E(\\mathbf \\mid \\mathbf _{i})=\\mathbf _{i}^{\\mathsf}B}\n",
      "\n",
      " is still assumed, with a matrix B replacing the vector β of the classical linear regression model. Multivariate analogues of ordinary least squares (OLS) and generalized least squares (GLS) have been developed. \"General linear models\" are also called \"multivariate linear models\". These are not the same as multivariable linear models (also called \"multiple linear models\").\n",
      "Various models have been created that allow for heteroscedasticity, i.e. the errors for different response variables may have different variances.  For example, weighted least squares is a method for estimating linear regression models when the response variables may have different error variances, possibly with correlated errors. (See also Weighted linear least squares, and Generalized least squares.) Heteroscedasticity-consistent standard errors is an improved method for use with uncorrelated but potentially heteroscedastic errors.\n",
      "Generalized linear models (GLMs) are a framework for modeling response variables that are bounded or discrete. This is used, for example:\n",
      "Generalized linear models allow for an arbitrary link function, g, that relates the mean of the response variable(s) to the predictors: \n",
      "\n",
      "\n",
      "\n",
      "E\n",
      "(\n",
      "Y\n",
      ")\n",
      "=\n",
      "\n",
      "g\n",
      "\n",
      "−\n",
      "1\n",
      "\n",
      "\n",
      "(\n",
      "X\n",
      "B\n",
      ")\n",
      "\n",
      "\n",
      "{\\displaystyle E(Y)=g^{-1}(XB)}\n",
      "\n",
      ". The link function is often related to the distribution of the response, and in particular it typically has the effect of transforming between the \n",
      "\n",
      "\n",
      "\n",
      "(\n",
      "−\n",
      "∞\n",
      ",\n",
      "∞\n",
      ")\n",
      "\n",
      "\n",
      "{\\displaystyle (-\\infty ,\\infty )}\n",
      "\n",
      " range of the linear predictor and the range of the response variable.\n",
      "Some common examples of GLMs are:\n",
      "Single index models allow some degree of nonlinearity in the relationship between x and y, while preserving the central role of the linear predictor β′x as in the classical linear regression model. Under certain conditions, simply applying OLS to data from a single-index model will consistently estimate β up to a proportionality constant.\n",
      "Hierarchical linear models (or multilevel regression) organizes the data into a hierarchy of regressions, for example where A is regressed on B, and B is regressed on C. It is often used where the variables of interest have a natural hierarchical structure such as in educational statistics, where students are nested in classrooms, classrooms are nested in schools, and schools are nested in some administrative grouping, such as a school district. The response variable might be a measure of student achievement such as a test score, and different covariates would be collected at the classroom, school, and school district levels.\n",
      "Errors-in-variables models (or \"measurement error models\") extend the traditional linear regression model to allow the predictor variables X to be observed with error. This error causes standard estimators of β to become biased. Generally, the form of bias is an attenuation, meaning that the effects are biased toward zero.\n",
      "A large number of procedures have been developed for parameter estimation and inference in linear regression. These methods differ in computational simplicity of algorithms, presence of a closed-form solution, robustness with respect to heavy-tailed distributions, and theoretical assumptions needed to validate desirable statistical properties such as consistency and asymptotic efficiency.\n",
      "Some of the more common estimation techniques for linear regression are summarized below.\n",
      "Let's assume that the independent variable is \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "[\n",
      "\n",
      "x\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "x\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      ",\n",
      "…\n",
      ",\n",
      "\n",
      "x\n",
      "\n",
      "m\n",
      "\n",
      "\n",
      "]\n",
      "\n",
      "\n",
      "{\\displaystyle}=}\n",
      "\n",
      " and the model's parameters are \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "[\n",
      "\n",
      "β\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "β\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      ",\n",
      "⋯\n",
      ",\n",
      "\n",
      "β\n",
      "\n",
      "m\n",
      "\n",
      "\n",
      "]\n",
      "\n",
      "\n",
      "{\\displaystyle}=}\n",
      "\n",
      ", then the model's prediction would be \n",
      "\n",
      "\n",
      "\n",
      "y\n",
      "≈\n",
      "\n",
      "β\n",
      "\n",
      "0\n",
      "\n",
      "\n",
      "+\n",
      "\n",
      "∑\n",
      "\n",
      "i\n",
      "=\n",
      "1\n",
      "\n",
      "\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "\n",
      "i\n",
      "\n",
      "\n",
      "×\n",
      "\n",
      "x\n",
      "\n",
      "i\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\\displaystyle y\\approx \\beta _{0}+\\sum _{i=1}^{m}\\beta _{i}\\times x_{i}}\n",
      "\n",
      ". If \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\\displaystyle}}\n",
      "\n",
      " is extended to  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "[\n",
      "1\n",
      ",\n",
      "\n",
      "x\n",
      "\n",
      "1\n",
      "\n",
      "\n",
      ",\n",
      "\n",
      "x\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      ",\n",
      "…\n",
      ",\n",
      "\n",
      "x\n",
      "\n",
      "m\n",
      "\n",
      "\n",
      "]\n",
      "\n",
      "\n",
      "{\\displaystyle}=}\n",
      "\n",
      " then  \n",
      "\n",
      "\n",
      "\n",
      "y\n",
      "\n",
      "\n",
      "{\\displaystyle y}\n",
      "\n",
      " would become a dot product of the parameter and the independent variable, i.e. \n",
      "\n",
      "\n",
      "\n",
      "y\n",
      "≈\n",
      "\n",
      "∑\n",
      "\n",
      "i\n",
      "=\n",
      "0\n",
      "\n",
      "\n",
      "m\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "\n",
      "i\n",
      "\n",
      "\n",
      "×\n",
      "\n",
      "x\n",
      "\n",
      "i\n",
      "\n",
      "\n",
      "=\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\\displaystyle y\\approx \\sum _{i=0}^{m}\\beta _{i}\\times x_{i}={\\vec}\\,\\,.\\,{\\vec}}\n",
      "\n",
      ". In the least-squares setting, the optimum parameter is defined as such that minimizes the sum of mean squared loss: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "^\n",
      "\n",
      "\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "\n",
      "\n",
      "\n",
      "arg min\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "L\n",
      "(\n",
      "D\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "=\n",
      "\n",
      "\n",
      "\n",
      "arg min\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "∑\n",
      "\n",
      "i\n",
      "=\n",
      "1\n",
      "\n",
      "\n",
      "n\n",
      "\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ".\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x\n",
      "\n",
      "i\n",
      "\n",
      "\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "−\n",
      "\n",
      "y\n",
      "\n",
      "i\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\\displaystyle}}={\\underset}{\\mbox{arg min}}}\\,L(D,{\\vec})={\\underset}{\\mbox{arg min}}}\\sum _{i=1}^{n}({\\vec}\\,.\\,{\\vec}}-y_{i})^{2}}\n",
      "\n",
      "\n",
      "Now putting the independent and dependent variables in matrices  \n",
      "\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "\n",
      "{\\displaystyle X}\n",
      "\n",
      " and \n",
      "\n",
      "\n",
      "\n",
      "Y\n",
      "\n",
      "\n",
      "{\\displaystyle Y}\n",
      "\n",
      " respectively, the loss function can be rewritten as:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "L\n",
      "(\n",
      "D\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "|\n",
      "\n",
      "X\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "−\n",
      "Y\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "2\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "(\n",
      "X\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "−\n",
      "Y\n",
      "\n",
      ")\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "(\n",
      "X\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "−\n",
      "Y\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "\n",
      "Y\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "Y\n",
      "−\n",
      "\n",
      "Y\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "−\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "Y\n",
      "+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\\displaystyleL(D,{\\vec})&=||X{\\vec}-Y||^{2}\\\\&=(X{\\vec}-Y)^{T}(X{\\vec}-Y)\\\\&=Y^{T}Y-Y^{T}X{\\vec}-{\\vec}^{T}X^{T}Y+{\\vec}^{T}X^{T}X{\\vec}\\end{aligned}}}\n",
      "\n",
      "\n",
      "As the loss is convex the optimum solution lies at gradient zero. The gradient of the loss function is:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "∂\n",
      "L\n",
      "(\n",
      "D\n",
      ",\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "\n",
      "∂\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "\n",
      "\n",
      "\n",
      "∂\n",
      "\n",
      "(\n",
      "\n",
      "\n",
      "Y\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "Y\n",
      "−\n",
      "\n",
      "Y\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "−\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "Y\n",
      "+\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "∂\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "−\n",
      "2\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "Y\n",
      "+\n",
      "2\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\\displaystyle{\\frac})}{\\partial}}}&={\\fracY-Y^{T}X{\\vec}-{\\vec}^{T}X^{T}Y+{\\vec}^{T}X^{T}X{\\vec}\\right)}{\\partial}}}\\\\&=-2X^{T}Y+2X^{T}X{\\vec}\\end{aligned}}}\n",
      "\n",
      "\n",
      "Setting the gradient to zero produces the optimum parameter:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "−\n",
      "2\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "Y\n",
      "\n",
      "\n",
      "\n",
      "+\n",
      "2\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "⇒\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "Y\n",
      "=\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "⇒\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "β\n",
      "^\n",
      "\n",
      "\n",
      "→\n",
      "\n",
      "\n",
      "\n",
      "=\n",
      "(\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      ")\n",
      "\n",
      "−\n",
      "1\n",
      "\n",
      "\n",
      "\n",
      "X\n",
      "\n",
      "T\n",
      "\n",
      "\n",
      "Y\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "{\\displaystyle-2X^{T}Y&+2X^{T}X{\\vec}=0\\\\&\\Rightarrow X^{T}Y=X^{T}X{\\vec}\\\\&\\Rightarrow}}=(X^{T}X)^{-1}X^{T}Y\\end{aligned}}}\n",
      "\n",
      "\n",
      "Linear least squares methods include mainly:\n",
      "Linear regression is widely used in biological, behavioral and social sciences to describe possible relationships between variables. It ranks as one of the most important tools used in these disciplines.\n",
      "A trend line represents a trend, the long-term movement in time series data after other components have been accounted for. It tells whether a particular data set (say GDP, oil prices or stock prices) have increased or decreased over the period of time. A trend line could simply be drawn by eye through a set of data points, but more properly their position and slope is calculated using statistical techniques like linear regression. Trend lines typically are straight lines, although some variations use higher degree polynomials depending on the degree of curvature desired in the line.\n",
      "Trend lines are sometimes used in business analytics to show changes in data over time. This has the advantage of being simple. Trend lines are often used to argue that a particular action or event (such as training, or an advertising campaign) caused observed changes at a point in time. This is a simple technique, and does not require a control group, experimental design, or a sophisticated analysis technique. However, it suffers from a lack of scientific validity in cases where other potential changes can affect the data.\n",
      "Early evidence relating tobacco smoking to mortality and morbidity came from observational studies employing regression analysis. In order to reduce spurious correlations when analyzing observational data, researchers usually include several variables in their regression models in addition to the variable of primary interest. For example, in a regression model in which cigarette smoking is the independent variable of primary interest and the dependent variable is lifespan measured in years, researchers might include education and income as additional independent variables, to ensure that any observed effect of smoking on lifespan is not due to those other socio-economic factors. However, it is never possible to include all possible confounding variables in an empirical analysis. For example, a hypothetical gene might increase mortality and also cause people to smoke more. For this reason, randomized controlled trials are often able to generate more compelling evidence of causal relationships than can be obtained using regression analyses of observational data. When controlled experiments are not feasible, variants of regression analysis such as instrumental variables regression may be used to attempt to estimate causal relationships from observational data.\n",
      "The capital asset pricing model uses linear regression as well as the concept of beta for analyzing and quantifying the systematic risk of an investment. This comes directly from the beta coefficient of the linear regression model that relates the return on the investment to the return on all risky assets.\n",
      "Linear regression is the predominant empirical tool in economics.  For example, it is used to predict consumption spending, fixed investment spending, inventory investment, purchases of a country's exports, spending on imports, the demand to hold liquid assets, labor demand, and labor supply.\n",
      "Linear regression finds application in a wide range of environmental science applications. In Canada, the Environmental Effects Monitoring Program uses statistical analyses on fish and benthic surveys to measure the effects of pulp mill or metal mine effluent on the aquatic ecosystem.\n",
      "Linear regression plays an important role in the field of artificial intelligence such as machine learning. The linear regression algorithm is one of the fundamental supervised machine-learning algorithms due to its relative simplicity and well-known properties.\n",
      "Least squares linear regression, as a means of finding a good rough linear fit to a set of points was performed by Legendre (1805) and Gauss (1809) for the prediction of planetary movement. Quetelet was responsible for making the procedure well-known and for using it extensively in the social sciences.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dis = col.find_one({\"topic\": 'linear regression'},{\"_id\": 0})\n",
    "for vals in dis.values():\n",
    "    print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
